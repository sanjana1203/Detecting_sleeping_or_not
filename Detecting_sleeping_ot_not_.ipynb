{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Dlm7S6Hqbm",
        "outputId": "e74e6e82-1511-4493-900f-91654df9de30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import HTML, display, clear_output\n",
        "from google.colab import output\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "T1lljQkTHzaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier(\n",
        "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        ")\n",
        "eye_cascade = cv2.CascadeClassifier(\n",
        "    cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
        ")\n"
      ],
      "metadata": {
        "id": "tU6jC_smIAvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_show(img_data):\n",
        "    clear_output(wait=True)   # âœ… removes OLD output immediately\n",
        "\n",
        "    img_bytes = base64.b64decode(img_data.split(',')[1])\n",
        "    img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
        "\n",
        "    status = \"NOT SLEEPING\"\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_gray = gray[y:y+h, x:x+w]\n",
        "        eyes = eye_cascade.detectMultiScale(face_gray, 1.1, 3)\n",
        "\n",
        "        if len(eyes) == 0:\n",
        "            status = \"SLEEPING\"\n",
        "\n",
        "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        f\"Status: {status}\",\n",
        "        (10, 35),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        1,\n",
        "        (0, 0, 255) if status == \"SLEEPING\" else (0, 255, 0),\n",
        "        2\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "-ITFjW9oIDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(img_data):\n",
        "    detect_and_show(img_data)\n",
        "\n",
        "output.register_callback('notebook.processFrame', process_frame)\n",
        "\n",
        "display(HTML('''\n",
        "<video id=\"video\" width=\"400\" autoplay playsinline></video><br><br>\n",
        "\n",
        "<button onclick=\"startCamera()\">ðŸ“· Start Camera</button>\n",
        "<button onclick=\"detect()\">â–¶ Detect</button>\n",
        "\n",
        "<script>\n",
        "let stream = null;\n",
        "\n",
        "async function startCamera() {\n",
        "    if (stream) return;\n",
        "    stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "    const video = document.getElementById(\"video\");\n",
        "    video.srcObject = stream;\n",
        "}\n",
        "\n",
        "function detect() {\n",
        "    if (!stream) {\n",
        "        alert(\"Start camera first\");\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    const video = document.getElementById(\"video\");\n",
        "    const canvas = document.createElement(\"canvas\");\n",
        "    canvas.width = video.videoWidth;\n",
        "    canvas.height = video.videoHeight;\n",
        "    canvas.getContext(\"2d\").drawImage(video, 0, 0);\n",
        "\n",
        "    // ðŸ”¥ Python handles output, JS does NOTHING else\n",
        "    google.colab.kernel.invokeFunction(\n",
        "        'notebook.processFrame',\n",
        "        [canvas.toDataURL('image/jpeg')],\n",
        "        {}\n",
        "    );\n",
        "}\n",
        "</script>\n",
        "'''))\n"
      ],
      "metadata": {
        "id": "pCsXxPBcIGJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "ed74fe95-4f74-4410-8fe8-eef902f11837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video id=\"video\" width=\"400\" autoplay playsinline></video><br><br>\n",
              "\n",
              "<button onclick=\"startCamera()\">ðŸ“· Start Camera</button>\n",
              "<button onclick=\"detect()\">â–¶ Detect</button>\n",
              "\n",
              "<script>\n",
              "let stream = null;\n",
              "\n",
              "async function startCamera() {\n",
              "    if (stream) return;\n",
              "    stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "    const video = document.getElementById(\"video\");\n",
              "    video.srcObject = stream;\n",
              "}\n",
              "\n",
              "function detect() {\n",
              "    if (!stream) {\n",
              "        alert(\"Start camera first\");\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    const video = document.getElementById(\"video\");\n",
              "    const canvas = document.createElement(\"canvas\");\n",
              "    canvas.width = video.videoWidth;\n",
              "    canvas.height = video.videoHeight;\n",
              "    canvas.getContext(\"2d\").drawImage(video, 0, 0);\n",
              "\n",
              "    // ðŸ”¥ Python handles output, JS does NOTHING else\n",
              "    google.colab.kernel.invokeFunction(\n",
              "        'notebook.processFrame',\n",
              "        [canvas.toDataURL('image/jpeg')],\n",
              "        {}\n",
              "    );\n",
              "}\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}